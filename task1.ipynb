{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_repo = \"./sample_java_repo/csc-java-course-spring-2023-key-value-store-EgorShibaev/\"\n",
    "method1_name = \"org.csc.java.spring2023.KeyValueStoreImplementation.openValueStream\"\n",
    "method2_name = \"org.csc.java.spring2023.KeyValueStoreImplementation.getIndexManager\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook supports only Java repository. \n",
    "\n",
    "For parsing Java code library `javalang` is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import javalang\n",
    "import os\n",
    "\n",
    "def extract_code_block(code: str, start_position: int) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the code block starting at the given position according to the opening and closing braces\n",
    "    :param code: Java or Kotlin code\n",
    "    :param start_position: position of the opening brace of the code block\n",
    "    :return: code block and end position of the code block\n",
    "    \"\"\"\n",
    "    open_braces = 0\n",
    "    code_block_start = start_position\n",
    "    code_block_end = -1\n",
    "\n",
    "    for i in range(start_position, len(code)):\n",
    "        if code[i] == \"{\":\n",
    "            open_braces += 1\n",
    "        elif code[i] == \"}\":\n",
    "            open_braces -= 1\n",
    "            if open_braces == 0:\n",
    "                code_block_end = i + 1\n",
    "                break\n",
    "\n",
    "    if code_block_end == -1:\n",
    "        raise ValueError(f\"Code block extraction failed\")\n",
    "\n",
    "    while code[code_block_start] == \"\\n\":\n",
    "        code_block_start += 1\n",
    "\n",
    "    return code[code_block_start:code_block_end], code_block_end\n",
    "\n",
    "\n",
    "\n",
    "def extract_method_code(java_source: str, class_name: str, method_name: str) -> str | None:\n",
    "    \"\"\"\n",
    "    This function extracts the code of the method with the\n",
    "    given name and class from the Java source code\n",
    "    :param java_source: Java source code\n",
    "    :param class_name: name of the class\n",
    "    :param method_name: name of the method\n",
    "    :return: code of the method\n",
    "    \"\"\"\n",
    "    tree = javalang.parse.parse(java_source)\n",
    "\n",
    "    for path, node in tree.filter(javalang.tree.MethodDeclaration):\n",
    "        if class_name == path[1][0].name and method_name == node.name:\n",
    "            start_line = node.position.line - 1\n",
    "            start_position = sum(len(line) + 1 for line in java_source.splitlines()[:start_line]) \\\n",
    "                             + node.position.column - 1\n",
    "            return extract_code_block(java_source, start_position)[0]\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_method_code_by_repo_path_and_fqname(path_to_repository: str, fully_qualified_name: str) -> str | None:\n",
    "    \"\"\"\n",
    "    This function extracts the code of the method with the\n",
    "    given fully qualified name from the repository\n",
    "    :param path_to_repository: path to the repository\n",
    "    :param fully_qualified_name: fully qualified name of the method\n",
    "    :return: code of the method\n",
    "    \"\"\"\n",
    "\n",
    "    if fully_qualified_name.count(\".\") >= 2:\n",
    "        package, class_name, method_name = fully_qualified_name.rsplit(\".\", 2)\n",
    "    else:\n",
    "        class_name, method_name = fully_qualified_name.rsplit(\".\", 1)\n",
    "        package = \"\"\n",
    "\n",
    "    package_path = package.replace(\".\", os.path.sep)\n",
    "    file_path = os.path.join(path_to_repository, \"src\", \"main\", \"java\", package_path, f\"{class_name}.java\")\n",
    "\n",
    "    with open(file_path, \"r\") as java_file:\n",
    "        java_source = java_file.read()\n",
    "\n",
    "    # Extract the method code\n",
    "    return extract_method_code(java_source, class_name, method_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "method1_code = extract_method_code_by_repo_path_and_fqname(path_to_repo, method1_name)\n",
    "method2_code = extract_method_code_by_repo_path_and_fqname(path_to_repo, method2_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InputStream openValueStream(byte[] key) throws IOException {\\n    Objects.requireNonNull(key);\\n    if (!contains(key)) {\\n      throw new IOException(\"No such key in store\");\\n    }\\n    check_closed();\\n\\n\\n    var blocks = indexManager.getFileBlocksLocations(key);\\n    var stream = InputStream.nullInputStream();\\n\\n    for (var block : blocks) {\\n      stream = new SequenceInputStream(stream, valueStoreManager.openBlockStream(block));\\n    }\\n    return stream;\\n  }'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method1_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IndexManager getIndexManager() {\\n    check_closed();\\n\\n    return indexManager;\\n  }'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method2_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try 3 different models for this task: two models which are trained on the Java code and one model which is trained on the text datasets. The first two models are `microsoft/CodeGPT-small-java-adaptedGPT2` and `neulab/codebert-java` from Huggingface and the third model is `all-MiniLM-L6-v2` from Sentence Transformer library.\n",
    "\n",
    "For each model, I find embeddings for each method in pairs and consider the cosine distance between embeddings as a similarity measure.\n",
    "\n",
    "I expect that models trained on Java code will extract meaningful features from the code and methods with similar semantics will be closer to each other.\n",
    "\n",
    "The model from Sentence Transformer is trained for the task of semantic textual similarity, so, it is probable that it will be suitable for code similarity tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# classes-wrappers for models from different sources\n",
    "class SentenceTransformerModel:\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def encode(self, method_code):\n",
    "        return self.model.encode(method_code, convert_to_tensor=True).view(1, -1)\n",
    "\n",
    "class HuggingfaceModel:\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    def encode(self, method_code):\n",
    "        inputs = self.tokenizer(method_code, return_tensors=\"pt\")\n",
    "        outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at neulab/codebert-java and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"CodeGPT\": HuggingfaceModel(\"microsoft/CodeGPT-small-java-adaptedGPT2\"),\n",
    "    \"CodeBERT\": HuggingfaceModel(\"neulab/codebert-java\"),\n",
    "    \"MiniLM\": SentenceTransformerModel(\"all-MiniLM-L6-v2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_similarity(model_name, method1_code, method2_code):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embedding_1 = models[model_name].encode(method1_code)\n",
    "        embedding_2 = models[model_name].encode(method2_code)\n",
    "\n",
    "    similarity = torch.nn.functional.cosine_similarity(embedding_1, embedding_2)\n",
    "\n",
    "    return similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity by CodeGPT: 0.535\n",
      "Similarity by CodeBERT: 0.911\n",
      "Similarity by MiniLM: 0.368\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    similarity = get_similarity(model_name, method1_code, method2_code)\n",
    "    print(f\"Similarity by {model_name}: {similarity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some comparison of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(code1, code2):\n",
    "    for model_name in models:\n",
    "        similarity = get_similarity(model_name, code1, code2)\n",
    "        print(f\"Similarity by {model_name}: {similarity:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity by CodeGPT: 0.441\n",
      "Similarity by CodeBERT: 0.906\n",
      "Similarity by MiniLM: 0.014\n"
     ]
    }
   ],
   "source": [
    "compare_models(\"\"\"\n",
    "public int factorial(int n) {\n",
    "    if (n == 0) {\n",
    "        return 1;\n",
    "    } else {\n",
    "        return n * factorial(n - 1);\n",
    "    }\n",
    "}\n",
    "\"\"\",\"\"\"\n",
    "public String[] parseCSVLine(String csvLine) {\n",
    "    return csvLine.split(\",\");\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity by CodeGPT: 0.672\n",
      "Similarity by CodeBERT: 0.902\n",
      "Similarity by MiniLM: 0.385\n"
     ]
    }
   ],
   "source": [
    "compare_models(\"\"\"\n",
    "public int calculateSquare(int num) {\n",
    "    return num * num;\n",
    "}\n",
    "\"\"\",\"\"\"\n",
    "public boolean isNumeric(String str) {\n",
    "    try {\n",
    "        Double.parseDouble(str);\n",
    "        return true;\n",
    "    } catch (NumberFormatException e) {\n",
    "        return false;\n",
    "    }\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity by CodeGPT: 0.453\n",
      "Similarity by CodeBERT: 0.867\n",
      "Similarity by MiniLM: 0.036\n"
     ]
    }
   ],
   "source": [
    "compare_models(\"\"\"\n",
    "public int findMax(int[] arr) {\n",
    "    int max = arr[0];\n",
    "    for (int i = 1; i < arr.length; i++) {\n",
    "        if (arr[i] > max) {\n",
    "            max = arr[i];\n",
    "        }\n",
    "    }\n",
    "    return max;\n",
    "}\n",
    "\"\"\",\"\"\"\n",
    "public String toUpperCase(String input) {\n",
    "    return input.toUpperCase();\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I consider methods below similar, so, I expect that the similarity score for them will be high.\n",
    "\n",
    " CodeGPT and CodeBERT output high score, but Sentence Transformer model output much lower score, so, it is not able to see similarity between these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity by CodeGPT: 0.968\n",
      "Similarity by CodeBERT: 0.998\n",
      "Similarity by MiniLM: 0.601\n"
     ]
    }
   ],
   "source": [
    "compare_models(\"\"\"\n",
    "public static int sum(List<Integer> numbers) {\n",
    "        int sum = 0;\n",
    "        for (int num : numbers) {\n",
    "            sum += num;\n",
    "        }\n",
    "        return sum;\n",
    "}\n",
    "\"\"\",\"\"\"\n",
    "public static int product(List<Integer> numbers) {\n",
    "        int product = 1;\n",
    "        for (int num : numbers) {\n",
    "            product *= num;\n",
    "        }\n",
    "        return product;\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity by CodeGPT: 0.840\n",
      "Similarity by CodeBERT: 0.973\n",
      "Similarity by MiniLM: 0.768\n"
     ]
    }
   ],
   "source": [
    "compare_models(\"\"\"\n",
    "public static int sqrt(int a) {\n",
    "    return a * a;\n",
    "}\n",
    "\"\"\",\"\"\"\n",
    "public static long sqrt(int a) {\n",
    "    return Math.pow(a, 2);\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume\n",
    "\n",
    "I compared 3 models on pairs of java methods. \n",
    "- all-MiniLM-L6-v2 from Sentence Transformers library is not the best choice for this task because it was trained on large amounts of text data to generate sentence embeddings that capture the semantic meaning of the __text__, so, it is not suitable for code similarity task.\n",
    "- CodeBERT always output high score, so, it should be taken into account.\n",
    "- CodeGPT seems to perform better than CodeBERT for this task. So, I will use CodeGPT for the second task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook task1.ipynb to html\n",
      "[NbConvertApp] Writing 646514 bytes to task1.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html task1.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
