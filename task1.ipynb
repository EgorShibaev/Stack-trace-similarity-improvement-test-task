{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_repo = \"./sample_java_repo/csc-java-course-spring-2023-key-value-store-EgorShibaev/\"\n",
    "method1_name = \"org.csc.java.spring2023.KeyValueStoreImplementation.openValueStream\"\n",
    "method2_name = \"org.csc.java.spring2023.KeyValueStoreImplementation.getIndexManager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def extract_method_code(repository_path, method_name):\n",
    "    \"\"\"\n",
    "    Extracts the code of the method with the given name from the repository\n",
    "    :param repository_path: path to the repository\n",
    "    :param method_name: name of the method to extract\n",
    "    :return: code of the method\n",
    "    \"\"\"\n",
    "    \n",
    "    package, class_name, method_name = method_name.rsplit(\".\", 2)\n",
    "    package_path = package.replace(\".\", os.path.sep)\n",
    "    file_path = os.path.join(repository_path, \"src\", \"main\", \"java\", package_path, f\"{class_name}.java\")\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    method_code = extract_method_code_from_content(content, method_name)\n",
    "    return method_code\n",
    "\n",
    "def extract_method_code_from_content(java_code, method_name):\n",
    "    \"\"\"\n",
    "    Extracts the code of the method with the given name from the Java code\n",
    "    :param java_code: Java code\n",
    "    :param method_name: name of the method to extract\n",
    "    :return: code of the method\n",
    "    \"\"\"\n",
    "\n",
    "    method_pattern = re.compile(rf\"\\n\\s*(\\w+\\s+)*{method_name}\\s*\\([^\\)]*\\)(\\s*throws\\s+[\\w,]+)?\\s*\\{{\")\n",
    "\n",
    "\n",
    "    match = method_pattern.search(java_code)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Method {method_name} not found in the Java code\")\n",
    "\n",
    "    open_braces = 0\n",
    "    method_start = match.start()\n",
    "    method_end = -1\n",
    "\n",
    "    for i in range(method_start, len(java_code)):\n",
    "        if java_code[i] == \"{\":\n",
    "            open_braces += 1\n",
    "        elif java_code[i] == \"}\":\n",
    "            open_braces -= 1\n",
    "            if open_braces == 0:\n",
    "                method_end = i + 1\n",
    "                break\n",
    "\n",
    "    if method_end == -1:\n",
    "        raise ValueError(f\"Method {method_name} code extraction failed\")\n",
    "\n",
    "    return java_code[method_start:method_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "method1_code = extract_method_code(path_to_repo, method1_name)\n",
    "method2_code = extract_method_code(path_to_repo, method2_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  public InputStream openValueStream(byte[] key) throws IOException {\\n    Objects.requireNonNull(key);\\n    if (!contains(key)) {\\n      throw new IOException(\"No such key in store\");\\n    }\\n    check_closed();\\n\\n\\n    var blocks = indexManager.getFileBlocksLocations(key);\\n    var stream = InputStream.nullInputStream();\\n\\n    for (var block : blocks) {\\n      stream = new SequenceInputStream(stream, valueStoreManager.openBlockStream(block));\\n    }\\n    return stream;\\n  }'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method1_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  public IndexManager getIndexManager() {\\n    check_closed();\\n\\n    return indexManager;\\n  }'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method2_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# classes-wrappers for different models\n",
    "class SentenceTransformerModel:\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def encode(self, method_code):\n",
    "        return self.model.encode(method_code, convert_to_tensor=True).view(1, -1)\n",
    "\n",
    "class HuggingfaceModel:\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    def encode(self, method_code):\n",
    "        inputs = self.tokenizer(method_code, return_tensors=\"pt\")\n",
    "        outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at neulab/codebert-java and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"CodeGPT\": HuggingfaceModel(\"microsoft/CodeGPT-small-java-adaptedGPT2\"),\n",
    "    \"CodeBERT\": HuggingfaceModel(\"neulab/codebert-java\"),\n",
    "    \"MiniLM\": SentenceTransformerModel(\"all-MiniLM-L6-v2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_similarity(model_name, method1_code, method2_code):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embedding_1 = models[model_name].encode(method1_code)\n",
    "        embedding_2 = models[model_name].encode(method2_code)\n",
    "\n",
    "    similarity = torch.nn.functional.cosine_similarity(embedding_1, embedding_2)\n",
    "\n",
    "    return similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity by CodeGPT: 0.660\n",
      "Similarity by CodeBERT: 0.920\n",
      "Similarity by MiniLM: 0.378\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    similarity = get_similarity(model_name, method1_code, method2_code)\n",
    "    print(f\"Similarity by {model_name}: {similarity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some comparison of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(code1, code2):\n",
    "    for model_name in models:\n",
    "        similarity = get_similarity(model_name, code1, code2)\n",
    "        print(f\"Similarity by {model_name}: {similarity:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity by CodeGPT: 0.441\n",
      "Similarity by CodeBERT: 0.906\n",
      "Similarity by MiniLM: 0.014\n"
     ]
    }
   ],
   "source": [
    "compare_models(\"\"\"\n",
    "public int factorial(int n) {\n",
    "    if (n == 0) {\n",
    "        return 1;\n",
    "    } else {\n",
    "        return n * factorial(n - 1);\n",
    "    }\n",
    "}\n",
    "\"\"\",\"\"\"\n",
    "public String[] parseCSVLine(String csvLine) {\n",
    "    return csvLine.split(\",\");\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity by CodeGPT: 0.672\n",
      "Similarity by CodeBERT: 0.902\n",
      "Similarity by MiniLM: 0.385\n"
     ]
    }
   ],
   "source": [
    "compare_models(\"\"\"\n",
    "public int calculateSquare(int num) {\n",
    "    return num * num;\n",
    "}\n",
    "\"\"\",\"\"\"\n",
    "public boolean isNumeric(String str) {\n",
    "    try {\n",
    "        Double.parseDouble(str);\n",
    "        return true;\n",
    "    } catch (NumberFormatException e) {\n",
    "        return false;\n",
    "    }\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity by CodeGPT: 0.453\n",
      "Similarity by CodeBERT: 0.867\n",
      "Similarity by MiniLM: 0.036\n"
     ]
    }
   ],
   "source": [
    "compare_models(\"\"\"\n",
    "public int findMax(int[] arr) {\n",
    "    int max = arr[0];\n",
    "    for (int i = 1; i < arr.length; i++) {\n",
    "        if (arr[i] > max) {\n",
    "            max = arr[i];\n",
    "        }\n",
    "    }\n",
    "    return max;\n",
    "}\n",
    "\"\"\",\"\"\"\n",
    "public String toUpperCase(String input) {\n",
    "    return input.toUpperCase();\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity by CodeGPT: 0.968\n",
      "Similarity by CodeBERT: 0.998\n",
      "Similarity by MiniLM: 0.601\n"
     ]
    }
   ],
   "source": [
    "compare_models(\"\"\"\n",
    "public static int sum(List<Integer> numbers) {\n",
    "        int sum = 0;\n",
    "        for (int num : numbers) {\n",
    "            sum += num;\n",
    "        }\n",
    "        return sum;\n",
    "}\n",
    "\"\"\",\"\"\"\n",
    "public static int product(List<Integer> numbers) {\n",
    "        int product = 1;\n",
    "        for (int num : numbers) {\n",
    "            product *= num;\n",
    "        }\n",
    "        return product;\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity by CodeGPT: 0.840\n",
      "Similarity by CodeBERT: 0.973\n",
      "Similarity by MiniLM: 0.768\n"
     ]
    }
   ],
   "source": [
    "compare_models(\"\"\"\n",
    "public static int sqrt(int a) {\n",
    "    return a * a;\n",
    "}\n",
    "\"\"\",\"\"\"\n",
    "public static long sqrt(int a) {\n",
    "    return Math.pow(a, 2);\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume\n",
    "\n",
    "I compared 3 models on pairs of java methods. \n",
    "- all-MiniLM-L6-v2 from Sentence Transformers library is not the best choice for this task because it was trained on large amounts of text data to generate sentence embeddings that capture the semantic meaning of the __text__, so, it is not suitable for code similarity task.\n",
    "- CodeGPT seems to perform better than CodeBERT for this task. So, I will use CodeGPT for the second task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook task1.ipynb to html\n",
      "[NbConvertApp] Writing 639698 bytes to task1.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html task1.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
